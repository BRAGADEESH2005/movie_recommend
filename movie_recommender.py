# -*- coding: utf-8 -*-
"""movie_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b51D8g-nwVh1Pv6BPm7dzeWyt8zQHUb4
"""

import numpy as np
import pandas as pd
import ast

movies = pd.read_csv("tmdb_5000_movies.csv")
credits = pd.read_csv("tmdb_5000_credits.csv")

movies.head(1)

movies.info()

credits.head(1)

movies=movies.merge(credits,on="title")

movies.shape

#genre,id,keywords,title,overview,cast,crew
movies = movies[['movie_id','title','cast','crew','keywords','overview','genres']]

movies.isnull().sum()

movies = movies[~movies.overview.isna()]

movies.duplicated().sum()

movies.iloc[0].genres

def convert(obj):
  l=[]
  for i in ast.literal_eval(obj):
    l.append(i["name"])
  return l

movies.genres = movies.genres.apply(convert)

movies.head()

movies.keywords = movies.keywords.apply(convert)

movies.cast[0]

# ast.literal_eval(movies.cast[0])
def convert3(obj):
  c=0
  l=[]
  for i in ast.literal_eval(obj):
    if c!= 3:
      l.append(i["name"])
      c+=1
    else:
      break
  return l

# convert3(movies.cast[0])
movies.cast = movies.cast.apply(convert3)

# ast.literal_eval(movies.crew[0])

def convert_dir(obj):
  l=[]
  for i in ast.literal_eval(obj):
    if i["job"]=="Director":
      l.append(i["name"])
      break
  return l

convert_dir(movies.crew[0])

movies.crew = movies.crew.apply(convert_dir)

movies.head()

movies.overview[0]

movies.overview = movies.overview.apply(lambda x: x.split())

movies.genres = movies.genres.apply(lambda x : [i.replace(" ","") for i in x])

movies.keywords = movies.keywords.apply(lambda x : [i.replace(" ","") for i in x])
movies.cast = movies.cast .apply(lambda x : [i.replace(" ","") for i in x])
movies.crew = movies.crew.apply(lambda x : [i.replace(" ","") for i in x])

movies.head()

movies['tags'] = movies['overview'] + movies['cast'] + movies['crew'] + movies['keywords'] + movies['genres']

movies.head(2)

df = movies[['movie_id','title','tags']]

df.head()

df.tags = df.tags.apply(lambda x : " ".join(x))

df.head()

df.tags[0]

df.tags = df.tags.apply(lambda x : x.lower())

df.head()

import nltk

from nltk.stem.porter import PorterStemmer
ps =PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():
    y.append(ps.stem(i))
  s=" ".join(y)
  return s

df.tags=df.tags.apply(stem)

df.tags

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,stop_words='english')

# do it after stemming
vectors = cv.fit_transform(df["tags"]).toarray()

# Get feature names
feature_names = cv.get_feature_names_out()
# for i in feature_names:
#   print(i)

from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vectors)

similarity

def recommend(movie):
  movie_index = df[df.title == movie].index[0]
  distances =similarity[movie_index]
  movies_list = sorted(list(enumerate(distances)),reverse=True,key = lambda x:x[1])[1:6]
  for i in movies_list:
    print(df.iloc[i[0]].title)

recommend("Avatar")

import pickle

pickle.dump(df.to_dict(),open("movie_dictf.pkl","wb"))

pickle.dump(similarity,open('similarity.pkl',"wb"))

